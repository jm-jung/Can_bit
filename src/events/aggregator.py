"""ì´ë²¤íŠ¸ â†’ íƒ€ìž„í”„ë ˆìž„ í”¼ì²˜ ì§‘ê³„ ë¡œì§."""
from __future__ import annotations

import logging
from datetime import datetime, timedelta, timezone
from typing import Iterable, List

import numpy as np
import pandas as pd

from src.events.schemas import Event, EventCategory

logger = logging.getLogger(__name__)


def aggregate_events(
    events: List[Event],
    timeline: Iterable[datetime],
    lookback_minutes: int = 60,
) -> pd.DataFrame:
    """ì£¼ì–´ì§„ íƒ€ìž„ë¼ì¸ì— ë§žì¶° ì´ë²¤íŠ¸ í”¼ì²˜ë¥¼ ìƒì„±."""
    timestamps = pd.to_datetime(list(timeline))
    if timestamps.empty:
        logger.warning("íƒ€ìž„ë¼ì¸ì´ ë¹„ì–´ìžˆì–´ ë¹ˆ DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return pd.DataFrame()

    # ðŸ”¥ DatetimeIndexëŠ” .dtê°€ ì—†ë‹¤ â†’ ë°”ë¡œ tz, tz_convert ì‚¬ìš©
    if isinstance(timestamps, pd.DatetimeIndex) and timestamps.tz is not None:
        # UTCë¡œ ë³€í™˜ í›„ tz ì •ë³´ë¥¼ ì œê±°í•˜ì—¬ tz-naiveë¡œ í†µì¼
        timestamps = timestamps.tz_convert("UTC").tz_localize(None)

    categories = list(EventCategory)
    if not events:
        logger.warning("ì§‘ê³„ ëŒ€ìƒ ì´ë²¤íŠ¸ê°€ ì—†ì–´ 0ìœ¼ë¡œ ì±„ìš´ í”¼ì²˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return _build_empty_features(timestamps, categories, lookback_minutes)

    # --------- ì´ë²¤íŠ¸ timestampë¥¼ tz-naive UTCë¡œ í†µì¼ ----------
    event_rows: list[dict] = []
    for ev in events:
        ev_ts = ev.timestamp
        
        # timezone-awareë¡œ ê°•ì œ ë³€í™˜ (ë‚´ë¶€ ê¸°ì¤€ì€ UTC)
        if ev_ts.tzinfo is None:
            ev_ts = ev_ts.replace(tzinfo=timezone.utc)
        else:
            ev_ts = ev_ts.astimezone(timezone.utc)
        
        # tz ì •ë³´ ì œê±° â†’ tz-naive UTC
        ev_ts = ev_ts.replace(tzinfo=None)
        
        event_rows.append({
            "timestamp": pd.to_datetime(ev_ts),
            "category": ev.category,
            "sentiment": ev.sentiment_score,
            "intensity": ev.intensity,
        })
    
    event_df = pd.DataFrame(event_rows)
    if event_df.empty:
        logger.warning("ì´ë²¤íŠ¸ DataFrameì´ ë¹„ì–´ìžˆì–´ 0ìœ¼ë¡œ ì±„ìš´ í”¼ì²˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return _build_empty_features(timestamps, categories, lookback_minutes)
    
    event_df.sort_values("timestamp", inplace=True)

    # --------- ì§‘ê³„ ---------
    feature_rows: list[dict] = []
    last_event_ts: datetime | None = None
    window_delta = timedelta(minutes=lookback_minutes)

    for ts in timestamps:
        # tsë„ tz-naive ìƒíƒœì´ë¯€ë¡œ windowë„ tz-naive
        window_start = ts - window_delta
        
        # tz-naiveë¼ë¦¬ ë¹„êµ â†’ ì—ëŸ¬ ì—†ìŒ
        mask = (event_df["timestamp"] > window_start) & (event_df["timestamp"] <= ts)
        window_events = event_df.loc[mask]

        if not window_events.empty:
            # max()ê°€ ë°˜í™˜í•˜ëŠ” Timestampë„ tz-naiveì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            last_event_ts = window_events["timestamp"].max().to_pydatetime()

        feature_rows.append(
            _compute_window_features(
                window_events,
                categories,
                ts,
                last_event_ts,
                lookback_minutes,
            )
        )

    feature_df = pd.DataFrame(feature_rows)
    if feature_df.empty:
        logger.warning("í”¼ì²˜ DataFrameì´ ë¹„ì–´ìžˆì–´ 0ìœ¼ë¡œ ì±„ìš´ í”¼ì²˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        return _build_empty_features(timestamps, categories, lookback_minutes)
    
    feature_df.set_index("timestamp", inplace=True)
    feature_df = feature_df.fillna(0.0)
    logger.debug(
        "ì´ë²¤íŠ¸ í”¼ì²˜ ì§‘ê³„ ì™„ë£Œ: shape=%s, ì»¬ëŸ¼=%s",
        feature_df.shape,
        list(feature_df.columns),
    )
    return feature_df


def _compute_window_features(
    window_events: pd.DataFrame,
    categories: List[EventCategory],
    current_ts: datetime,
    last_event_ts: datetime | None,
    lookback_minutes: int,
) -> dict:
    feature: dict[str, float | datetime] = {"timestamp": current_ts}
    total = int(len(window_events))
    feature["event_count_total"] = float(total)

    for category in categories:
        col = f"event_count_{category.value.lower()}"
        if total == 0:
            feature[col] = 0.0
        else:
            feature[col] = float((window_events["category"] == category).sum())

    if total == 0:
        feature["event_sentiment_mean"] = 0.0
        feature["event_sentiment_positive_mean"] = 0.0
        feature["event_sentiment_negative_mean"] = 0.0
        feature["event_max_intensity"] = 0.0
    else:
        sentiments = window_events["sentiment"]
        feature["event_sentiment_mean"] = float(np.clip(sentiments.mean(), -1.0, 1.0))
        positive = sentiments[sentiments > 0]
        negative = sentiments[sentiments < 0]
        feature["event_sentiment_positive_mean"] = float(
            np.clip(positive.mean() if not positive.empty else 0.0, 0.0, 1.0)
        )
        feature["event_sentiment_negative_mean"] = float(
            np.clip(negative.mean() if not negative.empty else 0.0, -1.0, 0.0)
        )
        feature["event_max_intensity"] = float(
            window_events["intensity"].max(skipna=True)
        )

    # Time since last event
    if last_event_ts is None:
        feature["event_time_since_last_min"] = float(lookback_minutes)
    else:
        delta_min = (current_ts - last_event_ts).total_seconds() / 60
        feature["event_time_since_last_min"] = float(max(delta_min, 0.0))

    # One-hot vectors (ë¹„ìœ¨)
    total_float = feature["event_count_total"] or 1.0
    for category in categories:
        count = feature[f"event_count_{category.value.lower()}"]
        feature[f"event_share_{category.value.lower()}"] = (
            float(count) / float(total_float) if total > 0 else 0.0
        )

    return feature


def _build_empty_features(
    timestamps: pd.DatetimeIndex,
    categories: List[EventCategory],
    lookback_minutes: int,
) -> pd.DataFrame:
    rows = []
    for ts in timestamps:
        base = {
            "timestamp": ts,
            "event_count_total": 0.0,
            "event_sentiment_mean": 0.0,
            "event_sentiment_positive_mean": 0.0,
            "event_sentiment_negative_mean": 0.0,
            "event_max_intensity": 0.0,
            "event_time_since_last_min": float(lookback_minutes),
        }
        for category in categories:
            base[f"event_count_{category.value.lower()}"] = 0.0
            base[f"event_share_{category.value.lower()}"] = 0.0
        rows.append(base)
    df = pd.DataFrame(rows)
    df.set_index("timestamp", inplace=True)
    return df


